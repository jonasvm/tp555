{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs5NKfdCzB5dodOjEbHPeY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Lista 7"],"metadata":{"id":"BSQeUhqEWkF3"}},{"cell_type":"markdown","source":["## Exercício 4.\n","\n","Exercício sobre árvores de decisão utilizando a métrica ID3: Considere o conjunto de treinamento para classificação de mamíferos dado na tabela abaixo."],"metadata":{"id":"UVOdvHZIWpP7"}},{"cell_type":"markdown","source":["Primeiro, entropia para a variável de saída Mammal?.\n","\n","    Total de amostras: 10\n","    Mammal = yes: 4\n","    Mammal = no: 6\n","\n","A entropia é calculada como:\n","H(Mammal)=−(410log⁡2410+610log⁡2610)\n","H(Mammal)=−(104​log2​104​+106​log2​106​)\n","\n","Calculando cada termo:\n","H(Mammal)≈−(0.4×log⁡20.4+0.6×log⁡20.6)≈0.971\n","H(Mammal)≈−(0.4×log2​0.4+0.6×log2​0.6)≈0.971\n","Passo 2: Calcular o Ganho de Informação para Cada Atributo\n","\n","Agora calculo do ganho de informação para cada um dos atributos:\n","\n","Dividimos as amostras em dois grupos com base em Body Temperature: \"warm-blooded\" (sangue quente) e \"cold-blooded\" (sangue frio).\n","\n","    Para Body Temperature = warm-blooded:\n","        Total de amostras: 5\n","        Mammal = yes: 4\n","        Mammal = no: 1\n","\n","H(Mammal | Body Temperature = warm-blooded)=−(45log⁡245+15log⁡215)≈0.722\n","H(Mammal | Body Temperature = warm-blooded)=−(54​log2​54​+51​log2​51​)≈0.722\n","\n","    Para Body Temperature = cold-blooded:\n","        Total de amostras: 5\n","        Mammal = yes: 0\n","        Mammal = no: 5\n","\n","H(Mammal | Body Temperature = cold-blooded)=−(1×log⁡21)=0\n","H(Mammal | Body Temperature = cold-blooded)=−(1×log2​1)=0\n","\n","A entropia condicional em relação a Body Temperature é:\n","H(Mammal | Body Temperature)=510×0.722+510×0=0.361\n","H(Mammal | Body Temperature)=105​×0.722+105​×0=0.361\n","\n","O ganho de informação para Body Temperature é:\n","Ganho(Body Temperature)=H(Mammal)−H(Mammal | Body Temperature)=0.971−0.361=0.61\n","Ganho(Body Temperature)=H(Mammal)−H(Mammal | Body Temperature)=0.971−0.361=0.61\n","Ganho de Informação para Gives Birth?\n","\n","Dividimos as amostras com base em Gives Birth? (\"yes\" ou \"no\").\n","\n","    Para Gives Birth = yes:\n","        Total de amostras: 5\n","        Mammal = yes: 4\n","        Mammal = no: 1\n","\n","H(Mammal | Gives Birth = yes)=−(45log⁡245+15log⁡215)≈0.722\n","H(Mammal | Gives Birth = yes)=−(54​log2​54​+51​log2​51​)≈0.722\n","\n","    Para Gives Birth = no:\n","        Total de amostras: 5\n","        Mammal = yes: 0\n","        Mammal = no: 5\n","\n","H(Mammal | Gives Birth = no)=−(1×log⁡21)=0\n","H(Mammal | Gives Birth = no)=−(1×log2​1)=0\n","\n","A entropia condicional em relação a Gives Birth? é:\n","H(Mammal | Gives Birth)=510×0.722+510×0=0.361\n","H(Mammal | Gives Birth)=105​×0.722+105​×0=0.361\n","\n","O ganho de informação para Gives Birth? é:\n","Ganho(Gives Birth)=H(Mammal)−H(Mammal | Gives Birth)=0.971−0.361=0.61\n","Ganho(Gives Birth)=H(Mammal)−H(Mammal | Gives Birth)=0.971−0.361=0.61\n","Ganho de Informação para Four-legged?\n","\n","Dividimos as amostras com base em Four-legged? (\"yes\" ou \"no\").\n","\n","    Para Four-legged = yes:\n","        Total de amostras: 4\n","        Mammal = yes: 2\n","        Mammal = no: 2\n","\n","H(Mammal | Four-legged = yes)=−(24log⁡224+24log⁡224)=1\n","H(Mammal | Four-legged = yes)=−(42​log2​42​+42​log2​42​)=1\n","\n","    Para Four-legged = no:\n","        Total de amostras: 6\n","        Mammal = yes: 2\n","        Mammal = no: 4\n","\n","H(Mammal | Four-legged = no)=−(26log⁡226+46log⁡246)≈0.918\n","H(Mammal | Four-legged = no)=−(62​log2​62​+64​log2​64​)≈0.918\n","\n","A entropia condicional em relação a Four-legged? é:\n","H(Mammal | Four-legged)=410×1+610×0.918=0.951\n","H(Mammal | Four-legged)=104​×1+106​×0.918=0.951\n","\n","O ganho de informação para Four-legged? é:\n","Ganho(Four-legged)=H(Mammal)−H(Mammal | Four-legged)=0.971−0.951=0.02\n","Ganho(Four-legged)=H(Mammal)−H(Mammal | Four-legged)=0.971−0.951=0.02\n","Ganho de Informação para Hibernates?\n","\n","Dividimos as amostras com base em Hibernates? (\"yes\" ou \"no\").\n","\n","    Para Hibernates = yes:\n","        Total de amostras: 4\n","        Mammal = yes: 2\n","        Mammal = no: 2\n","\n","H(Mammal | Hibernates = yes)=1\n","H(Mammal | Hibernates = yes)=1\n","\n","    Para Hibernates = no:\n","        Total de amostras: 6\n","        Mammal = yes: 2\n","        Mammal = no: 4\n","\n","H(Mammal | Hibernates = no)=0.918\n","H(Mammal | Hibernates = no)=0.918\n","\n","A entropia condicional em relação a Hibernates? é:\n","H(Mammal | Hibernates)=0.951\n","H(Mammal | Hibernates)=0.951\n","\n","O ganho de informação para Hibernates? é:\n","Ganho(Hibernates)\n","Ganho(Hibernates)"],"metadata":{"id":"f1SlrkQCWUln"}},{"cell_type":"markdown","source":["Escolha do Atributo para o Primeiro Nó\n","\n","Com base nos cálculos, os atributos Body Temperature e Gives Birth? têm os maiores ganhos de informação (0.61). Podemos escolher qualquer um desses dois atributos como o nó raiz da árvore.\n","\n","Para este exemplo, vamos escolher Body Temperature como o primeiro nó.\n","Construção da Árvore de Decisão\n","\n","    Primeiro Nó (Raiz): Body Temperature\n","\n","        Para Body Temperature = warm-blooded:\n","            Com este valor, temos 5 exemplos, dos quais 4 têm \"Mammal = yes\" e 1 tem \"Mammal = no\".\n","            Com uma maioria de \"yes\", classificamos essa subdivisão como yes (mamífero).\n","\n","        Para Body Temperature = cold-blooded:\n","            Com este valor, temos 5 exemplos, todos com \"Mammal = no\".\n","            Então, classificamos essa subdivisão como no (não é mamífero).\n","\n","Classificação\n","\n","Nossa árvore de decisão é agora:\n","\n","    Se Body Temperature = warm-blooded, então Mammal = yes.\n","    Se Body Temperature = cold-blooded, então Mammal = no.\n","\n","\n"],"metadata":{"id":"_dVWe97yWhJX"}},{"cell_type":"markdown","source":["Item 2"],"metadata":{"id":"Tb3l3GjcZMAj"}},{"cell_type":"markdown","source":["Respostas às Perguntas do Exercício\n","\n","    Existem atributos que podem ser descartados?\n","        Sim, com esta árvore, os atributos Gives Birth?, Four-legged?, e Hibernates? não são necessários, pois Body Temperature já classifica corretamente todos os exemplos.\n","\n","    Outras aplicações das árvores de decisão além da classificação:\n","        Árvores de decisão podem ser usadas para regressão, análise de risco, diagnóstico médico, e suporte na tomada de decisões em várias áreas.\n","\n","    Classificação de novos exemplos de teste:\n","        Com a árvore construída, podemos classificar outros animais testando apenas se eles são \"warm-blooded\" ou \"cold-blooded\"."],"metadata":{"id":"rr_COeWZZHWV"}},{"cell_type":"markdown","source":["Item 3"],"metadata":{"id":"-FKI2DdEY-XV"}},{"cell_type":"markdown","source":["Árvores de decisão, além de classificarem dados, também podem ser utilizadas para:\n","\n","    Regressão: A árvore pode ser adaptada para prever valores contínuos. Em vez de usar a maioria das classes para decisões, a árvore calcula a média (ou outro valor central) das amostras em cada nó.\n","    Análise de risco: Árvores de decisão são frequentemente usadas para modelar decisões em ambientes incertos, ajudando a avaliar as consequências e o risco de cada escolha.\n","    Diagnóstico médico: Podem ser aplicadas para classificar ou prever condições médicas baseadas em sintomas ou características do paciente.\n","    Suporte à tomada de decisões: Árvores de decisão ajudam a visualizar as possíveis consequências de decisões, permitindo escolher a opção mais vantajosa com base em critérios bem definidos."],"metadata":{"id":"JgEgTj77YDns"}},{"cell_type":"markdown","source":["Item 4"],"metadata":{"id":"8m8y9mI2ZTPq"}},{"cell_type":"markdown","source":["Vamos agora usar a árvore construída para classificar os exemplos de teste fornecidos. A árvore de decisão tem o seguinte formato:\n","\n","    Se Body Temperature = warm-blooded, então Mammal = yes.\n","    Se Body Temperature = cold-blooded, então Mammal = no."],"metadata":{"id":"Y0fMAu_sYQX2"}},{"cell_type":"markdown","source":["Classificação segundo a árvore de decisão:\n","\n","    human: warm-blooded → Mammal = yes (correto)\n","    pigeon: warm-blooded → Mammal = yes (errado, deveria ser no)\n","    elephant: warm-blooded → Mammal = yes (correto)\n","    turtle: cold-blooded → Mammal = no (correto)\n","    penguin: warm-blooded → Mammal = yes (errado, deveria ser no)\n","    dolphin: warm-blooded → Mammal = yes (correto)\n","    platypus: warm-blooded → Mammal = yes (correto)\n","    spiny anteater: warm-blooded → Mammal = yes (correto)\n","\n","Erros de classificação:\n","\n","    Pigeon: foi classificado como Mammal = yes, mas a classe correta é Mammal = no.\n","    Penguin: foi classificado como Mammal = yes, mas a classe correta é Mammal = no."],"metadata":{"id":"k_FvETVhYRJ5"}},{"cell_type":"markdown","source":["Item 5"],"metadata":{"id":"qKN0pqmHZaf_"}},{"cell_type":"markdown","source":["Sim, houve erros de classificação:\n","\n","    Pigeon foi classificado como Mammal = yes, mas deveria ser Mammal = no.\n","    Penguin foi classificado como Mammal = yes, mas deveria ser Mammal = no."],"metadata":{"id":"8CQYjQB1YUYu"}},{"cell_type":"markdown","source":["Item 6 e Item 7"],"metadata":{"id":"3dUX8HalZdxO"}},{"cell_type":"markdown","source":["Para melhorar a acurácia, o atributo Body Temperature não está fornecendo uma distinção suficiente entre todas as classes. Podemos considerar outros atributos que também influenciam a classificação, como Gives Birth?, Four-legged? e Hibernates?, para aumentar a complexidade da árvore e possibilitar uma divisão mais precisa.\n","Construção de uma nova árvore de decisão (considerando mais atributos):\n","\n","    A partir dos cálculos de ganho de informação, o próximo atributo com maior ganho foi Gives Birth? (ganho de 0.61), após o Body Temperature. Portanto, podemos expandir a árvore incluindo Gives Birth?.\n","\n","Construção da nova árvore:\n","\n","    Body Temperature:\n","        Se warm-blooded, então verificar Gives Birth?:\n","            yes → Mammal = yes.\n","            no → Mammal = no.\n","        Se cold-blooded, então Mammal = no.\n","\n","Nova árvore de decisão:"],"metadata":{"id":"5oMEKdJpYYlD"}},{"cell_type":"markdown","source":["Se Body Temperature = warm-blooded:\n","\n","    Se Gives Birth? = yes → Mammal = yes\n","    Se Gives Birth? = no → Mammal = no\n","    \n","Se Body Temperature = cold-blooded → Mammal = no\n"],"metadata":{"id":"tKTQAaf7Ygjq"}},{"cell_type":"markdown","source":["Vamos usar a nova árvore de decisão para classificar novamente os exemplos:\n","\n","    human: warm-blooded → Gives Birth? = yes → Mammal = yes (correto)\n","    pigeon: warm-blooded → Gives Birth? = no → Mammal = no (correto)\n","    elephant: warm-blooded → Gives Birth? = yes → Mammal = yes (correto)\n","    turtle: cold-blooded → Mammal = no (correto)\n","    penguin: warm-blooded → Gives Birth? = no → Mammal = no (correto)\n","    dolphin: warm-blooded → Gives Birth? = yes → Mammal = yes (correto)\n","    platypus: warm-blooded → Gives Birth? = no → Mammal = yes (errado, deveria ser no)\n","    spiny anteater: warm-blooded → Gives Birth? = no → Mammal = yes (errado, deveria ser no)\n","\n","Erros de classificação na nova árvore:\n","\n","    Platypus: foi classificado como Mammal = yes, mas deveria ser Mammal = no.\n","    Spiny anteater: foi classificado como Mammal = yes, mas deveria ser Mammal = no.\n","\n","A nova árvore não alcançou 100% de acurácia, mas melhorou a acurácia com relação à anterior."],"metadata":{"id":"hJQhLbzrYh9p"}}]}